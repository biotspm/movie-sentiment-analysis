{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Objective\n",
    "\n",
    "Build Multiple Models and Emsemble the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function  # Python 2/3 compatibility\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>2060</td>\n",
       "      <td>0</td>\n",
       "      <td>Daphne Zuniga is the only light that shines in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7142</th>\n",
       "      <td>7142</td>\n",
       "      <td>1</td>\n",
       "      <td>And that's why historic/biographic movies are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>5907</td>\n",
       "      <td>0</td>\n",
       "      <td>I tend to like character-driven films. I also ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24544</th>\n",
       "      <td>24544</td>\n",
       "      <td>0</td>\n",
       "      <td>Is Miike like Chabrol, alternating art with dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11448</th>\n",
       "      <td>11448</td>\n",
       "      <td>1</td>\n",
       "      <td>All I can say is, first movie this season that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22770</th>\n",
       "      <td>22770</td>\n",
       "      <td>0</td>\n",
       "      <td>An MTV-style film crew consisting of American ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13059</th>\n",
       "      <td>13059</td>\n",
       "      <td>0</td>\n",
       "      <td>Someone here actually compared this movie in s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15380</th>\n",
       "      <td>15380</td>\n",
       "      <td>1</td>\n",
       "      <td>This isn't the best romantic comedy ever made,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>I watched the un-aired episodes online and I w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4465</th>\n",
       "      <td>4465</td>\n",
       "      <td>0</td>\n",
       "      <td>OK, the story - a simpleminded loony enters a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       document_id  sentiment  \\\n",
       "2060          2060          0   \n",
       "7142          7142          1   \n",
       "5907          5907          0   \n",
       "24544        24544          0   \n",
       "11448        11448          1   \n",
       "22770        22770          0   \n",
       "13059        13059          0   \n",
       "15380        15380          1   \n",
       "2022          2022          1   \n",
       "4465          4465          0   \n",
       "\n",
       "                                                  review  \n",
       "2060   Daphne Zuniga is the only light that shines in...  \n",
       "7142   And that's why historic/biographic movies are ...  \n",
       "5907   I tend to like character-driven films. I also ...  \n",
       "24544  Is Miike like Chabrol, alternating art with dr...  \n",
       "11448  All I can say is, first movie this season that...  \n",
       "22770  An MTV-style film crew consisting of American ...  \n",
       "13059  Someone here actually compared this movie in s...  \n",
       "15380  This isn't the best romantic comedy ever made,...  \n",
       "2022   I watched the un-aired episodes online and I w...  \n",
       "4465   OK, the story - a simpleminded loony enters a ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training process\n",
    "\n",
    "* Split the Overall Training examples into Training and Validation\n",
    "* Build the Models on Training Data\n",
    "* Score on Validation data\n",
    "* Choose the best model and submit to Kaggle\n",
    "\n",
    "\n",
    "Caution:  If you do this enough times, you will be overfitting to the Validation data.  To avoid that it might be advisable to split into three ways like Train-Validation-Test and generate the final score on Test Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_df[\"review\"], train_df[\"sentiment\"], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 20000, Validation: 5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data: {}, Validation: {}\".format(len(X_train), len(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Vectorize Data (a.k.a. covert text to numbers)\n",
    "\n",
    "Computers don't understand Texts, so we need to convert texts to numbers before we could do any math on it and see if we can build a system to classify a review as Positive or Negative.\n",
    "\n",
    "Ways to vectorize data:\n",
    "\n",
    "* Bag of Words\n",
    "* TF-IDF\n",
    "* Word Embeddings (Word2Vec) \n",
    "\n",
    "Scikit-Learn has nice APIs for preprocessing and feature extraction modules.  In fact, these can be used even if you build your own models or use another libriary for model building process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The API is very similar to model building process.\n",
    "# Step 1: Instantiate the Vectorizer or more generally called Transformer\n",
    "\n",
    "vect = CountVectorizer(max_features=5000, binary=True, stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Fit your Training Data\n",
    "vect.fit(X_train)\n",
    "\n",
    "# Transform your training and validation data\n",
    "X_train_vect = vect.transform(X_train)\n",
    "X_valid_vect = vect.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model - Logistic Regression\n",
    "\n",
    "* Logistic Regression\n",
    "* Naive Bayes\n",
    "* Neural Nets\n",
    "* Random Forest\n",
    "* Gradient Boosted Trees\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model 1 - Logisitc Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = LogisticRegression()\n",
    "model_1.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.967\n",
      "Validation Accuracy: 0.854\n"
     ]
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "print(\"Training Accuracy: {:.3f}\".format(model_1.score(X_train_vect, y_train)))\n",
    "print(\"Validation Accuracy: {:.3f}\".format(model_1.score(X_valid_vect, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model 2 - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = MultinomialNB()\n",
    "model_2.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.866\n",
      "Validation Accuracy: 0.845\n"
     ]
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "print(\"Training Accuracy: {:.3f}\".format(model_2.score(X_train_vect, y_train)))\n",
    "print(\"Validation Accuracy: {:.3f}\".format(model_2.score(X_valid_vect, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model 3 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=3,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=25, n_jobs=-1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = RandomForestClassifier(min_samples_leaf=3, n_estimators=25, n_jobs=-1)\n",
    "model_3.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.949\n",
      "Validation Accuracy: 0.820\n"
     ]
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "print(\"Training Accuracy: {:.3f}\".format(model_3.score(X_train_vect, y_train)))\n",
    "print(\"Validation Accuracy: {:.3f}\".format(model_3.score(X_valid_vect, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model 4 - Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=3,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=25, n_jobs=-1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4 = RandomForestClassifier(min_samples_leaf=3, n_estimators=25, n_jobs=-1)\n",
    "model_4.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.946\n",
      "Validation Accuracy: 0.822\n"
     ]
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "print(\"Training Accuracy: {:.3f}\".format(model_4.score(X_train_vect, y_train)))\n",
    "print(\"Validation Accuracy: {:.3f}\".format(model_4.score(X_valid_vect, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Model 5 - Neural Networks (CPU Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(32,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5 = MLPClassifier(hidden_layer_sizes=(32,), max_iter=100)\n",
    "model_5.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.000\n",
      "Validation Accuracy: 0.839\n"
     ]
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "print(\"Training Accuracy: {:.3f}\".format(model_5.score(X_train_vect, y_train)))\n",
    "print(\"Validation Accuracy: {:.3f}\".format(model_5.score(X_valid_vect, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Neural Nets** - Textbook Case of Overfitting.  Maybe the model is too powerful :-D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model Tuning\n",
    "\n",
    "* All these models have tons of Parameters that could be tweaked to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Finding it difficult to pick the Winning Model - Why not Average the Results\n",
    "\n",
    "* After all we collectively make the right decisions, on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classifiers = [(\"Logistic Regression\", model_1), \n",
    "               (\"Naive Bayes\", model_2), \n",
    "               (\"Random Forest\", model_3), \n",
    "               (\"Gradient Boosted\", model_4), \n",
    "               (\"Neural Nets\", model_5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Logistic Regression',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "            verbose=0, warm_start=False)),\n",
       " ('Naive Bayes', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)),\n",
       " ('Random Forest',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=3,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=25, n_jobs=-1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False)),\n",
       " ('Gradient Boosted',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=3,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=25, n_jobs=-1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False)),\n",
       " ('Neural Nets',\n",
       "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "         beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "         hidden_layer_sizes=(32,), learning_rate='constant',\n",
       "         learning_rate_init=0.001, max_iter=100, momentum=0.9,\n",
       "         nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "         shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "         verbose=False, warm_start=False))]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "final_model = VotingClassifier(classifiers, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Logistic Regression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)...=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False))],\n",
       "         n_jobs=-1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unfortuately, have to run Fit Again on the ensembled model before using it\n",
    "# Wish there was an option to not have to fit again\n",
    "final_model.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.965\n",
      "Validation Accuracy: 0.866\n"
     ]
    }
   ],
   "source": [
    "# Drum Rolls - Accuracy on the final Model\n",
    "print(\"Training Accuracy: {:.3f}\".format(final_model.score(X_train_vect, y_train)))\n",
    "print(\"Validation Accuracy: {:.3f}\".format(final_model.score(X_valid_vect, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Let's Update Kaggle Submission\n",
    "\n",
    "Steps:\n",
    "\n",
    "* Load Test Dataset\n",
    "* Vectorize the Features (Review)\n",
    "* Predict the sentiment\n",
    "* Create the CSV file and update the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This is one of those movies that has everythin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't know what some people were thinking wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Here is a rundown of a typical Rachael Ray Sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Speck\" was apparently intended to be a biopic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Let's get it clear from the start: I am an ass...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document_id                                             review\n",
       "0            0  This is one of those movies that has everythin...\n",
       "1            1  I don't know what some people were thinking wh...\n",
       "2            2  Here is a rundown of a typical Rachael Ray Sho...\n",
       "3            3  \"Speck\" was apparently intended to be a biopic...\n",
       "4            4  Let's get it clear from the start: I am an ass..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the Test Dataset\n",
    "# Note that it's missing the Sentiment Column.  That's what we need to Predict\n",
    "#\n",
    "test_df = pd.read_csv(\"data/test.tsv\", sep=\"\\t\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Vectorize the Review Text\n",
    "\n",
    "X_test = test_df.review\n",
    "X_test_vect = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = final_model.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"document_id\": test_df.document_id,\n",
    "    \"sentiment\": y_test_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"data/ensemble_submission1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Other Ideas\n",
    "\n",
    "* Try Different Vectorizers\n",
    "* Hyper Parameter Tuning of Models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
