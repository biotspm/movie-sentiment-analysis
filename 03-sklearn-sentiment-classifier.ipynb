{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Objective\n",
    "\n",
    "Build a Sentiment Classifier using Logistic Regression:\n",
    "\n",
    "* Load Data\n",
    "* Vectorize using Scikit-Learn\n",
    "* Build a Logisitc Regression Model\n",
    "* Evaluate the Model\n",
    "* Update our Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function  # Python 2/3 compatibility\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/train.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14903</th>\n",
       "      <td>14903</td>\n",
       "      <td>1</td>\n",
       "      <td>i would never have thought that it would be po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196</th>\n",
       "      <td>17196</td>\n",
       "      <td>0</td>\n",
       "      <td>I give this movie a ONE, for it is truly an aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23684</th>\n",
       "      <td>23684</td>\n",
       "      <td>0</td>\n",
       "      <td>Visually disjointed and full of itself, the di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19603</th>\n",
       "      <td>19603</td>\n",
       "      <td>0</td>\n",
       "      <td>I've seen about 820 movies released between 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9412</th>\n",
       "      <td>9412</td>\n",
       "      <td>1</td>\n",
       "      <td>The movie begins a with mentally-challenged gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6905</th>\n",
       "      <td>6905</td>\n",
       "      <td>0</td>\n",
       "      <td>This movie should be nominated for a new genre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>8637</td>\n",
       "      <td>0</td>\n",
       "      <td>i guess its possible that I've seen worse movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5177</th>\n",
       "      <td>5177</td>\n",
       "      <td>1</td>\n",
       "      <td>Of course you could never go into a theatre an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15110</th>\n",
       "      <td>15110</td>\n",
       "      <td>0</td>\n",
       "      <td>I absolutely adore the 'Toxic Avenger' series,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>4798</td>\n",
       "      <td>0</td>\n",
       "      <td>Where the hell are all these uncharted islands...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       document_id  sentiment  \\\n",
       "14903        14903          1   \n",
       "17196        17196          0   \n",
       "23684        23684          0   \n",
       "19603        19603          0   \n",
       "9412          9412          1   \n",
       "6905          6905          0   \n",
       "8637          8637          0   \n",
       "5177          5177          1   \n",
       "15110        15110          0   \n",
       "4798          4798          0   \n",
       "\n",
       "                                                  review  \n",
       "14903  i would never have thought that it would be po...  \n",
       "17196  I give this movie a ONE, for it is truly an aw...  \n",
       "23684  Visually disjointed and full of itself, the di...  \n",
       "19603  I've seen about 820 movies released between 19...  \n",
       "9412   The movie begins a with mentally-challenged gi...  \n",
       "6905   This movie should be nominated for a new genre...  \n",
       "8637   i guess its possible that I've seen worse movi...  \n",
       "5177   Of course you could never go into a theatre an...  \n",
       "15110  I absolutely adore the 'Toxic Avenger' series,...  \n",
       "4798   Where the hell are all these uncharted islands...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training process\n",
    "\n",
    "* Split the Overall Training examples into Training and Validation\n",
    "* Build the Models on Training Data\n",
    "* Score on Validation data\n",
    "* Choose the best model and submit to Kaggle\n",
    "\n",
    "\n",
    "Caution:  If you do this enough times, you will be overfitting to the Validation data.  To avoid that it might be advisable to split into three ways like Train-Validation-Test and generate the final score on Test Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_df[\"review\"], train_df[\"sentiment\"], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: 20000, Validation: 5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data: {}, Validation: {}\".format(len(X_train), len(X_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Vectorize Data (a.k.a. covert text to numbers)\n",
    "\n",
    "Computers don't understand Texts, so we need to convert texts to numbers before we could do any math on it and see if we can build a system to classify a review as Positive or Negative.\n",
    "\n",
    "Ways to vectorize data:\n",
    "\n",
    "* Bag of Words\n",
    "* TF-IDF\n",
    "* Word Embeddings (Word2Vec) \n",
    "\n",
    "Scikit-Learn has nice APIs for preprocessing and feature extraction modules.  In fact, these can be used even if you build your own models or use another libriary for model building process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The API is very similar to model building process.\n",
    "# Step 1: Instantiate the Vectorizer or more generally called Transformer\n",
    "\n",
    "vect = CountVectorizer(max_features=5000, binary=True, stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Fit your Training Data\n",
    "vect.fit(X_train)\n",
    "\n",
    "# Transform your training and validation data\n",
    "X_train_vect = vect.transform(X_train)\n",
    "X_valid_vect = vect.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1181     The Order starts in Rome where the head of a s...\n",
       "6139     While \"Santa Claus Conquers the Martians\" is u...\n",
       "7145     This film is horribly acted, written, directed...\n",
       "9375     \"In the world of old-school kung fu movies, wh...\n",
       "24185    A charming boy and his mother move to a middle...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20000x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1426615 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a Sparse Matrix\n",
    "X_train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Understand the Vectorizer\n",
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Does similar things to what we did manually in our bag of words model\n",
    "\n",
    "# vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kiss', 2514),\n",
       " ('blatant', 503),\n",
       " ('elizabeth', 1483),\n",
       " ('screenwriter', 3881),\n",
       " ('santa', 3832),\n",
       " ('ruined', 3801),\n",
       " ('nazi', 2987),\n",
       " ('length', 2599),\n",
       " ('cable', 640),\n",
       " ('sexuality', 3956)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Does similar things to what we did manually in our bag of words model\n",
    "from itertools import islice\n",
    "\n",
    "list(islice(vect.vocabulary_.items(), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kiss</th>\n",
       "      <th>blatant</th>\n",
       "      <th>elizabeth</th>\n",
       "      <th>screenwriter</th>\n",
       "      <th>santa</th>\n",
       "      <th>ruined</th>\n",
       "      <th>nazi</th>\n",
       "      <th>length</th>\n",
       "      <th>cable</th>\n",
       "      <th>sexuality</th>\n",
       "      <th>...</th>\n",
       "      <th>adults</th>\n",
       "      <th>pick</th>\n",
       "      <th>underground</th>\n",
       "      <th>distance</th>\n",
       "      <th>seemingly</th>\n",
       "      <th>drunken</th>\n",
       "      <th>soundtrack</th>\n",
       "      <th>technical</th>\n",
       "      <th>appeared</th>\n",
       "      <th>confess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   kiss  blatant  elizabeth  screenwriter  santa  ruined  nazi  length  cable  \\\n",
       "0     0        1          0             1      0       0     0       0      0   \n",
       "1     0        0          0             0      0       0     0       0      0   \n",
       "2     0        0          0             0      0       0     0       0      0   \n",
       "3     0        0          0             0      0       0     0       0      0   \n",
       "4     0        0          0             0      0       0     0       0      0   \n",
       "\n",
       "   sexuality   ...     adults  pick  underground  distance  seemingly  \\\n",
       "0          0   ...          0     1            0         0          0   \n",
       "1          0   ...          0     0            0         0          0   \n",
       "2          0   ...          0     0            0         0          0   \n",
       "3          0   ...          0     0            0         0          0   \n",
       "4          0   ...          0     0            0         0          0   \n",
       "\n",
       "   drunken  soundtrack  technical  appeared  confess  \n",
       "0        0           0          0         0        0  \n",
       "1        0           0          0         0        0  \n",
       "2        0           0          0         0        0  \n",
       "3        0           0          0         0        0  \n",
       "4        0           0          0         0        0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_vect.todense(), columns=vect.vocabulary_.keys()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.964\n"
     ]
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "print(\"Training Accuracy: {:.3f}\".format(model.score(X_train_vect, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.854\n"
     ]
    }
   ],
   "source": [
    "## Validation Accuracy\n",
    "print(\"Validation Accuracy: {:.3f}\".format(model.score(X_valid_vect, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model Tuning\n",
    "\n",
    "Model seems to be Overfitting.  Try, Regularization to bring Training Accuracy closer to Validation Accuracy\n",
    "\n",
    "* What options are available in Logisitc Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=0.1)\n",
    "model.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.934\n",
      "Validation Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "# Training Accuracy\n",
    "print(\"Training Accuracy: {:.3f}\".format(model.score(X_train_vect, y_train)))\n",
    "print(\"Validation Accuracy: {:.3f}\".format(model.score(X_valid_vect, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feeling Good? - Let's Update Kaggle Submission\n",
    "\n",
    "Steps:\n",
    "\n",
    "* Load Test Dataset\n",
    "* Vectorize the Features (Review)\n",
    "* Predict the sentiment\n",
    "* Create the CSV file and update the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This is one of those movies that has everythin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I don't know what some people were thinking wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Here is a rundown of a typical Rachael Ray Sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Speck\" was apparently intended to be a biopic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Let's get it clear from the start: I am an ass...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document_id                                             review\n",
       "0            0  This is one of those movies that has everythin...\n",
       "1            1  I don't know what some people were thinking wh...\n",
       "2            2  Here is a rundown of a typical Rachael Ray Sho...\n",
       "3            3  \"Speck\" was apparently intended to be a biopic...\n",
       "4            4  Let's get it clear from the start: I am an ass..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the Test Dataset\n",
    "# Note that it's missing the Sentiment Column.  That's what we need to Predict\n",
    "#\n",
    "test_df = pd.read_csv(\"data/test.tsv\", sep=\"\\t\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Vectorize the Review Text\n",
    "\n",
    "X_test = test_df.review\n",
    "X_test_vect = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"document_id\": test_df.document_id,\n",
    "    \"sentiment\": y_test_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"data/logistic_reg_submission1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document_id,sentiment\r\n",
      "0,1\r\n",
      "1,1\r\n",
      "2,0\r\n",
      "3,0\r\n",
      "4,0\r\n",
      "5,0\r\n",
      "6,0\r\n",
      "7,0\r\n",
      "8,0\r\n"
     ]
    }
   ],
   "source": [
    "!head data/logistic_reg_submission1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## The End\n",
    "\n",
    "* Now your turn, Open the 04-compete notebook and try different Classifiers and see if you can improve the predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
